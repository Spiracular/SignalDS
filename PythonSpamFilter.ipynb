{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Spirapple/anaconda/lib/python3.5/site-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import nltk.data\n",
    "from gensim.models import Word2Vec\n",
    "from bs4 import BeautifulSoup\n",
    "#Note from opinions on stackoverflow: lxml.html is same as BS(\"lxml\")\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import email.parser\n",
    "import os, sys, stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = nltk.data.load(\"tokenizers/punkt/english.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load data and separate into train and test\n",
    "\n",
    "[CrossValidation in sklearn](http://scikit-learn.org/0.17/modules/cross_validation.html#cross-validation)\n",
    "\n",
    "Reading it in may actually be somewhat challenging; I'll want to keep the Subject line, mark bolding or italics (mm... later, once I've grabbed just-text)... lets try to get to running it faster, shall we? \n",
    "\n",
    "\n",
    "Wonderful terrible idea! Count BOTH the bolded-mark words as words and the regular-type of the bolded words. Doubles-down on the value of bolded-up words, but that seems fine, you know? (and easier to implement)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Spirapple/Desktop/Projects/PythonDataSci/SignalDS'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "?codecs.open()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_name = \"data/CSDMC2010_SPAM/CSDMC2010_SPAM/OUTPUT/TRAIN_00000.eml\"\n",
    "TestingEmail_0 = codecs.open(file_name, mode=\"r\", encoding='utf-8',errors='ignore')\n",
    "TestingEmail_0 = BeautifulSoup(TestingEmail_0, \"lxml\")\n",
    "#TestingEmail_0= BeautifulSoup(open(\"data/CSDMC2010_SPAM/CSDMC2010_SPAM/OUTPUT/TRAIN_00000.eml\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_name = \"data/CSDMC2010_SPAM/CSDMC2010_SPAM/OUTPUT/TRAIN_00001.eml\"\n",
    "TestingEmail_1 = codecs.open(file_name, mode=\"r\", encoding='utf-8',errors='ignore')\n",
    "TestingEmail_1 = BeautifulSoup(TestingEmail_1, \"lxml\")\n",
    "#TestingEmail_0= BeautifulSoup(open(\"data/CSDMC2010_SPAM/CSDMC2010_SPAM/OUTPUT/TRAIN_00000.eml\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelSpam = open(\"data/CSDMC2010_SPAM/CSDMC2010_SPAM/SPAMTrain.label\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0 TRAIN_00000.eml\\n'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelSpam.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get the labels (code from Will Levine)\n",
    "num_messages = 4327\n",
    "labels = np.zeros(num_messages, dtype=np.int)\n",
    "with open(\"data/CSDMC2010_SPAM/CSDMC2010_SPAM/SPAMTrain.label\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        labels[i] = int(line[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'link to my webcam you wanted Wanna see sexually curious teens playing with each other?\\n\\nhttp://www.site-personals.com '"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestingEmail_1.getText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['link',\n",
       " 'to',\n",
       " 'my',\n",
       " 'webcam',\n",
       " 'you',\n",
       " 'wanted',\n",
       " 'Wan',\n",
       " 'na',\n",
       " 'see',\n",
       " 'sexually',\n",
       " 'curious',\n",
       " 'teens',\n",
       " 'playing',\n",
       " 'with',\n",
       " 'each',\n",
       " 'other',\n",
       " '?',\n",
       " 'http',\n",
       " ':',\n",
       " '//www.site-personals.com']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getSubjectWords(TestingEmail_1) #adequate! Screw it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "readInSpam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Oh right, I can use nltk's tokenizer. I do need the specialized stuff for getting subject line,\n",
    "#but otherwise it's really simpler than I'm making it!\n",
    "\n",
    "#punkt added as tokenizer above\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['link',\n",
       " 'to',\n",
       " 'my',\n",
       " 'webcam',\n",
       " 'you',\n",
       " 'wanted',\n",
       " 'Wan',\n",
       " 'na',\n",
       " 'see',\n",
       " 'sexually',\n",
       " 'curious',\n",
       " 'teens',\n",
       " 'playing',\n",
       " 'with',\n",
       " 'each',\n",
       " 'other',\n",
       " '?',\n",
       " 'http',\n",
       " ':',\n",
       " '//www.site-personals.com']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getWordsFile(\"data/CSDMC2010_SPAM/CSDMC2010_SPAM/OUTPUT/TRAIN_00001.eml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def readInSpam(filename):\n",
    "    file_name = filename\n",
    "    mail = codecs.open(file_name, mode=\"r\", encoding='utf-8',errors='ignore')\n",
    "    souply = BeautifulSoup(mail, \"lxml\")\n",
    "    return (souply)\n",
    "\n",
    "def getSubjectWords(souply):\n",
    "    header = souply('p')[0]\n",
    "    header = header.getText()\n",
    "    #strlist = re.findall(\"\\w+\", header)\n",
    "    strlist = nltk.word_tokenize(header) #Yes, nltk and punkt does a great job!\n",
    "    return(strlist)\n",
    "\n",
    "def getWordsFile(filename):\n",
    "    souply = readInSpam(filename)\n",
    "    txtfile = souply.getText()\n",
    "    return(nltk.word_tokenize(txtfile))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def boldMark(souply):\n",
    "    bolds = souply('b')\n",
    "    bwordlist = []\n",
    "    for b in BOLD:\n",
    "        btext = b.getText()\n",
    "        strlist = [\"BB\"+s for s in re.findall(\"\\w+\", btext)]\n",
    "        bwordlist.append(strlist)\n",
    "    \n",
    "    return(bwordlist)\n",
    "\n",
    "def italMark(souply):\n",
    "    italics = souply('i')\n",
    "    iwordlist = []\n",
    "    for it in italics:\n",
    "        itext = it.getText()\n",
    "        strlist = [\"ii\"+s for s in re.findall(\"\\w+\", btext)]\n",
    "        iwordlist.append(strlist)\n",
    "    \n",
    "    return(iwordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#spam labels stored in labels; 0=spam 1=ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filelist = os.listdir(\"data/CSDMC2010_SPAM/CSDMC2010_SPAM/OUTPUT/\")\n",
    "#Name of all files in directory\n",
    "\n",
    "#len = 4327"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "?np.floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #Make index cv splits (it looks like sklearn's cv would be overkill)\n",
    "# total = 4327\n",
    "# fract = int(np.floor(4327/10))\n",
    "\n",
    "# random.seed(3)\n",
    "\n",
    "# fullindex =range(0,4327)\n",
    "# indextest = random.sample(fullindex, fract)\n",
    "# #432\n",
    "\n",
    "# indextrain  = np.array(filter(lambda a: a not in indextest, fullindex))\n",
    "# #3895\n",
    "# #range(0,4327) - indextest\n",
    "\n",
    "# #AUGH, using these outputs to index is an enormous pain!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3895"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indextrain)\n",
    "#Note: np arrays let you do multi-indexing, lists don't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Inventory\n",
    "#- labels;  0=spam 1=ham\n",
    "#- filelist; list of names of files -> filei (indexable pd.Series)\n",
    "#- get all words getWordsFile(filename)\n",
    "#- get subject lines: getSubjectWords(readInSpam(filename))\n",
    "#- get Bold: boldMark(readInSpam(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TFlabels = np.array(labels, dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.Series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Slap an index on filelist\n",
    "filei = pd.Series(filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Fuse together file names, test/train, and ham designation\n",
    "filehamdf = pd.concat({\"filenames\":filei, \"ham\":pd.Series(TFlabels)}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filenames</th>\n",
       "      <th>ham</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_00001.eml</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_00002.eml</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_00003.eml</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         filenames    ham\n",
       "1  TRAIN_00001.eml  False\n",
       "2  TRAIN_00002.eml   True\n",
       "3  TRAIN_00003.eml  False"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filehamdf[1:4] #problem: 1 is the title index. Will need to edit idices to work, augh..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filenames</th>\n",
       "      <th>ham</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>TRAIN_03199.eml</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            filenames    ham\n",
       "3199  TRAIN_03199.eml  False"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filehamdf.sample() #Good, default behavior is drawing from rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Step 1: Generate list names_of_files until filename doesn't exist in corpus.\n",
    "\n",
    "#Step 2: Read in files\n",
    "\n",
    "#Step 2.25: CV splits\n",
    "#Step 2.5: Sort destination folders by spam-label\n",
    "    #Step 3: collect words into bins (SpamSubject, SpamBody, HamSubject, HamBody)\n",
    "    ####Implementation: if sequence just defines the file pointer\n",
    "    ###(for syntactic clarity and code-reusability)\n",
    "    #Step 3.5: store bins as a text file? (Or just top words and probs?)\n",
    "    ###Implementation Question: Dictionary for number of occurences?\n",
    "    ###Counts table on text file?\n",
    "    ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define function that takes in dataframe and output destination's filename, and spits out the words.\n",
    "\n",
    "def wordSpit(spamdf, hamdf):\n",
    "    dataprep = \"data/CSDMC2010_SPAM/CSDMC2010_SPAM/TRAINING/\"\n",
    "    spamfiles = spamdf[\"filenames\"]\n",
    "    hamfiles = hamdf[\"filenames\"]\n",
    "    spamwords = []\n",
    "    hamwords = []\n",
    "    for filename in spamfiles:\n",
    "        spamwords+= getWordsFile(dataprep+filename)\n",
    "    for filename in hamfiles:\n",
    "        hamwords += getWordsFile(dataprep+filename)\n",
    "    return(spamwords, hamwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indextrain.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1949,\n",
       " 1068,\n",
       " 3030,\n",
       " 3883,\n",
       " 536,\n",
       " 107,\n",
       " 3843,\n",
       " 2124,\n",
       " 1919,\n",
       " 1570,\n",
       " 3852,\n",
       " 3902,\n",
       " 3253,\n",
       " 1233,\n",
       " 1899,\n",
       " 1242,\n",
       " 4285,\n",
       " 3194,\n",
       " 124,\n",
       " 524]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indextest[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trains = filehamdf.sample(frac=1/10, replace=False, random_state = 3,\\\n",
    "                         axis=0)\n",
    "#pd.Series()\n",
    "TFS = np.array(trains[[\"ham\"]], dtype=bool)\n",
    "spams = trains[ ~TFS ]\n",
    "hams = trains[ TFS ]\n",
    "spamwords, hamwords = wordSpit(spams, hams)\n",
    "#hamfiles = filei[TFlabels]\n",
    "#spamfiles = filei[!TFlabels]\n",
    "\n",
    "###This works, but it also eats up SO MUCH memory while it does so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['From',\n",
       " 'rssfeeds',\n",
       " '@',\n",
       " 'jmason.org',\n",
       " 'Wed',\n",
       " 'Sep',\n",
       " '25',\n",
       " '10:23:43',\n",
       " '2002',\n",
       " 'Return-Path']"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamwords[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def review_to_sentences(review, tokenizer, rm_stopwords = False):\n",
    "#     raw_sentences = tokenizer.tokenize(review.strip())\n",
    "#     sentences = []\n",
    "#     for raw_sentence in raw_sentences:\n",
    "#         if len(raw_sentence)>0:\n",
    "#             sentences.append(review_to_wordslist(raw_sentence, rm_stopwords))\n",
    "#     return(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True, False, False], dtype=bool)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = []\n",
    "for review in train[\"review\"]:\n",
    "    sentences += review_to_sentences(review, tokenizer)\n",
    "    #Note: In this unusual context, append will not behave while += would.\n",
    "for review in addtrain[\"review\"]:\n",
    "    sentences += review_to_sentences(review, tokenizer)\n",
    "\n",
    "    \n",
    "    ###Look into how review was generated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes Filter in sklearn](http://scikit-learn.org/stable/modules/naive_bayes.html)\n",
    "(Assumes independence between features)\n",
    "\n",
    "sklearn has MultinomialNB, take in data as word vector counts\n",
    "\n",
    "Could feed in word counts, but no reason it wouldn't also work for tf-idf it says.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick description of Paul Graham's Naive Bayes Filter\n",
    "\n",
    "    (let ((g (* 2 (or (gethash word good) 0)))\n",
    "          (b (or (gethash word bad) 0)))\n",
    "       (unless (< (+ g b) 5)\n",
    "         (max .01\n",
    "              (min .99 (float (/ (min 1 (/ b nbad))\n",
    "                                 (+ (min 1 (/ g ngood))   \n",
    "                                    (min 1 (/ b nbad)))))))))\n",
    "\n",
    "2\\*(gethash(word good) OR 0)\n",
    "\n",
    "min (1, (g/ngood + b/nbad))\n",
    "\n",
    "MAP = Maximum A Posteriori (MAP) estimation? or map function?\n",
    "\n",
    "Decent classifier, bad predictive estimator.\n",
    "\n",
    "Combining Probabilities\n",
    "\n",
    "    (let ((prod (apply #'* probs)))\n",
    "      (/ prod (+ prod (apply #'* (mapcar #'(lambda (x) \n",
    "                                             (- 1 x))\n",
    "                                         probs)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Implement Elastic Net Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Implement Naive Bayes Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html><body><p>One of a kind Money maker! Try it for free!From nobody Thu Oct 27 12:31:52 2016\n",
       "Content-Type: text/html;\n",
       "\tcharset=\"iso-8859-1\"\n",
       "Content-Transfer-Encoding: 7bit\n",
       "\n",
       "</p>\n",
       "<div class=\"Section1\">\n",
       "<p class=\"MsoBodyText\" style=\"text-align:justify\"><b>CONSANTLY</b> being\n",
       "bombarded by so-called FREE money-making systems that teases you with limited\n",
       "information, and when its all said and done, blind-sides you by demanding your\n",
       "money/credit card information upfront in some slick way,<b> after-the-fact</b>!\n",
       "Yes, I too was as skeptical about such offers and the Internet in general with\n",
       "all its hype, as you probably are. Fortunate for me, my main business\n",
       "slowed-down (<i>I have been self-employed all my life</i>), so I looked for\n",
       "something to fit my lifestyle and some other way to assist me in paying my\n",
       "bills, without working myself to death or loosing more money; then, this\n",
       "proposal to try something new without any upfront investment (<i>great! because\n",
       "I had none</i>) interested me to click on the link provided. And I dont regret\n",
       "at all that I did! I am very happy, and happy enough to recommend it to you as\n",
       "a system that is true to its word. I mean absolutely no upfront money. You join\n",
       "only if (<i>when</i>) you make money. You also get to track the results of your\n",
       "time and efforts instantly and updated daily! I especially liked this idea of\n",
       "personal control with real-time, staying informed statistics.</p>\n",
       "<p class=\"MsoBodyText\" style=\"text-align:justify\"><b>This system is quite simply\n",
       "the most logical, opened, and fair of any others that Ive seen before. Why?\n",
       "Because from the start, you get all the specific facts you need to seriously\n",
       "consider if this is right for you. No teasing. No grand testimonies! No\n",
       "kidding! Just the facts! Unlike in other programs that give you no idea of\n",
       "their overall plan before first forking over your money/credit card; or worst\n",
       "yet, joining and finding-out too late, after wasting valuable time trying to\n",
       "figure them out, this system is straightforward and informative, providing you\n",
       "with the two things you really must know: <u>Whats it all about</u>? and <u>How\n",
       "does it work</u>?. These are the ultimate deal makers or deal breakers that\n",
       "need to be immediately disclosed, well before discovering that maybe you dont\n",
       "want to do that; by then you are hooked and now locked into a frustrating\n",
       "battle to try to get your money back! </b></p>\n",
       "<p class=\"MsoBodyText\" style=\"text-align:justify\">I call this my Platinum\n",
       "Choice because it stands alone as a true, superior deal that is totally\n",
       "different from previously misleading, hook-first programs that promise lofty\n",
       "mega-money jackpots, but really just want your money upfront to line their own\n",
       "pockets! Youve seen the headlines: <u>Join free and Make $10,000 every week\n",
       "for life</u> yeah, right!</p>\n",
       "<p class=\"MsoBodyText\" style=\"text-align:justify\">I did not make millions yet,\n",
       "but the whole thing was launched just a few weeks ago and I am more than happy\n",
       "with my earnings, so far. I must tell you, I wouldnt be able to do anything\n",
       "without corporate help  which was unusually thorough, timely, and motivating. </p>\n",
       "<p class=\"MsoBodyText\" style=\"text-align:justify\">You have to see this in action\n",
       "for yourself and make up your own mind; just go to my site and fill out the\n",
       "form as soon as you can. You will get your own site in a few minutes. Then you\n",
       "are ready to try whether you can make some decent money with this system and\n",
       "the Internets explosive potential - fully loaded with hi-tech software, free\n",
       "corporate help, on-time members support and even protective safeguards! </p>\n",
       "<p class=\"MsoBodyText\" style=\"text-align:justify\">Get it now, and you can call me\n",
       "at any time with questions. It really could help you like it is helping me to\n",
       "finally be able to pay my bills, and keep my free time free. Good luck!</p>\n",
       "<p class=\"MsoBodyText\" style=\"text-align:justify\"><a href=\"http://www.mindupmerchants.com/default.asp?ID=5581\">http://www.mindupmerchants.com/default.asp?ID=5581</a></p>\n",
       "<p class=\"MsoBodyText\" style=\"text-align:justify\">Ben Green, (775) 322-3323 </p>\n",
       "<p class=\"MsoBodyText\">P.S.Free POP3 email is ofered for members now!</p>\n",
       "</div>\n",
       "</body></html>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestingEmail_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-b1d6d68566d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTestingEmail_0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "TestingEmail_0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['One',\n",
       " 'of',\n",
       " 'a',\n",
       " 'kind',\n",
       " 'Money',\n",
       " 'maker',\n",
       " 'Try',\n",
       " 'it',\n",
       " 'for',\n",
       " 'free',\n",
       " 'From',\n",
       " 'nobody',\n",
       " 'Thu',\n",
       " 'Oct',\n",
       " '27',\n",
       " '12',\n",
       " '31',\n",
       " '52',\n",
       " '2016',\n",
       " 'Content',\n",
       " 'Type',\n",
       " 'text',\n",
       " 'html',\n",
       " 'charset',\n",
       " 'iso',\n",
       " '8859',\n",
       " '1',\n",
       " 'Content',\n",
       " 'Transfer',\n",
       " 'Encoding',\n",
       " '7bit',\n",
       " '!',\n",
       " '!']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sample instance code to grab the subject line\n",
    "\n",
    "header = TestingEmail_0('p')[0] #Title information; try to swipe first line from here and train\n",
    "#separately, if you can.\n",
    "header = header.getText()\n",
    "\n",
    "#stringhead = header.prettify()\n",
    "#header.split('\\n')[0]\n",
    "\n",
    "re.findall(\"\\w+\", header) + re.findall(\"[?$!]\",header)\n",
    "#\"\\w+\"\n",
    "\n",
    "#Funny idea: find out how predictive \"[?$!]\" alone are of spam.\n",
    "\n",
    "#append B* or I* to everything with bold or italics, maybe?\n",
    "#We do want to keep caps...\n",
    "#I want to be able to grab the Subject line, but that might not be trivial, unfortunately...\n",
    "#Ignore numbers, for now?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONSANTLY\n",
      " after-the-fact\n",
      "This system is quite simply\n",
      "the most logical, opened, and fair of any others that Ive seen before. Why?\n",
      "Because from the start, you get all the specific facts you need to seriously\n",
      "consider if this is right for you. No teasing. No grand testimonies! No\n",
      "kidding! Just the facts! Unlike in other programs that give you no idea of\n",
      "their overall plan before first forking over your money/credit card; or worst\n",
      "yet, joining and finding-out too late, after wasting valuable time trying to\n",
      "figure them out, this system is straightforward and informative, providing you\n",
      "with the two things you really must know: Whats it all about? and How\n",
      "does it work?. These are the ultimate deal makers or deal breakers that\n",
      "need to be immediately disclosed, well before discovering that maybe you dont\n",
      "want to do that; by then you are hooked and now locked into a frustrating\n",
      "battle to try to get your money back! \n"
     ]
    }
   ],
   "source": [
    "BOLD = TestingEmail_0('b')\n",
    "for b in BOLD:\n",
    "    print(b.getText())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
